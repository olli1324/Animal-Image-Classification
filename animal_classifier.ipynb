{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olli1324/Animal-Image-Classification/blob/develop/animal_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9iA-ffeycrs"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI-yV37s0HH_"
      },
      "source": [
        "This is an image classifier, which can sort dogs and cats apart from eachother. We start with a dataset of raw data in JPEG format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEU-Sof5yiGT"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "B93KvX8JyGdD"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import os\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import data as tf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gDhhmllyXQ_"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ4eVCsXzONh"
      },
      "source": [
        "### Download raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqe78g12zQy1",
        "outputId": "11f5a72d-1784-4ab5-a488-1fe30d935328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  786M  100  786M    0     0  73.5M      0  0:00:10  0:00:10 --:--:-- 35.1M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsPBL2QxzR1H",
        "outputId": "3698ac11-19bf-487c-9653-956bbc6d43f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace PetImages/Cat/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPziLee3iDr"
      },
      "source": [
        "We now have a folder `PetImages`, with two subfolders, `Cat` and `Dog`. This is where the images will be categorized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl93x9FZ31tj"
      },
      "outputs": [],
      "source": [
        "!ls PetImages/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwYIW_BW4n5D"
      },
      "source": [
        "## Filter out corrupted files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7glofNA4tRb"
      },
      "source": [
        "When we work with data, corrupted files may occur. So we filter out badly encoded files, that don't feature the string \"JFIF\" in their header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyaVXRCv4r5C"
      },
      "outputs": [],
      "source": [
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "  folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "  for fname in os.listdir(folder_path):\n",
        "    fpath = os.path.join(folder_path, fname)\n",
        "    try:\n",
        "      fobj = open(fpath, \"rb\")\n",
        "      is_jfif = b\"JFIF\" in fobj.peek(10)\n",
        "    finally: fobj.close()\n",
        "\n",
        "    if not is_jfif:\n",
        "      num_skipped += 1\n",
        "      #remove corrupted file\n",
        "      os.remove(fpath)\n",
        "\n",
        "print(f\"Deleted {num_skipped} corrupted images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Dataset"
      ],
      "metadata": {
        "id": "FnSMxVRYxl6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GdNLAD6BUOG"
      },
      "outputs": [],
      "source": [
        "image_size = (180, 180)\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the data"
      ],
      "metadata": {
        "id": "bRwnyvKzx3Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "wd34rIdBx3ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Image Augmentation"
      ],
      "metadata": {
        "id": "wiaItlMb_w5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "]\n",
        "\n",
        "\n",
        "def data_augmentation(images):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images"
      ],
      "metadata": {
        "id": "agj8VQJx_xDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the Augmented Images"
      ],
      "metadata": {
        "id": "SI-_NMuBBEc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3 , 3, i+1)\n",
        "        augmented_images = data_augmentation(images)\n",
        "        plt.imshow(np.array(augmented_images[0].numpy().astype(\"uint8\")))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "q4EMqJHiBDsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standardize and rescale the data"
      ],
      "metadata": {
        "id": "CS616caaG5PU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images are already in a standard size (180x180). But their RGB channel values are in the [0, 255] range. This is not ideal for a neural network. We will standardize the values to be in the [0, 1] by using a Rescaling layer at the start of our model."
      ],
      "metadata": {
        "id": "mjLm_-V9JmCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=image_size)\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)"
      ],
      "metadata": {
        "id": "uRsjyWOpG8nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure datset for performance"
      ],
      "metadata": {
        "id": "lbNhVvcO7_xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply data_augmentation to the training images.\n",
        "train_ds = train_ds.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf_data.AUTOTUNE,)\n",
        "\n",
        "# Prefetching samples from the GPU to maximize GPU utilization.\n",
        "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "BJjYNy1p8Hov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a model"
      ],
      "metadata": {
        "id": "CIZTZjMua7l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        units = 1\n",
        "    else:\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    # We specify activation=None so as to return logits\n",
        "    outputs = layers.Dense(units, activation=None)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "FQ0TSlooY0Hg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsZpFJ9kQqBOZXmy+BMm/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}